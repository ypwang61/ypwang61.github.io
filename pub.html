<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="icon" type="image/png" sizes="32x32" href="photos/22_icon.png">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Papers</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yiping Wang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="pub.html" class="current">Publications</a></div>
<!-- <div class="menu-item"><a href="blog&thoughts.html">Blog & Thoughts</a></div> -->
<div class="menu-item"><a href="CV_YipingWang_phd.pdf">CV</a></div>
<div class="menu-item"><a href="miscellaneous.html">Miscellaneous</a></div>
<div class="menu-item"><a href="fun.html">Fun</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>

<p>For the updated list, check out my <a href="https://scholar.google.com/citations?user=IuMFxFUAAAAJ&amp;hl=en&amp;oi=ao">Google Scholar</a> page. <br /></p>
<p><span class="preserve-space">(* denotes equal contribution or alphabetic ordering, &dagger; denotes corresponding author)</span> <br /><br /></p>


<!-- <h1 style="color: black;">2025</h1> -->




<div class="boxed">
<ul>
  <li><p>
    <b>Reinforcement Learning for Reasoning in Large Language Models with One Training Example</b>
  <br>
  <b>Yiping Wang&dagger;</b>, Qing Yang, Zhiyuan Zeng, Liliang Ren, Lucas Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, Weizhu Chen, Shuohang Wang&dagger;, Simon Shaolei Du&dagger;, Yelong Shen&dagger;
  <br>
  <i><font color="red">#1 Paper</font> of the day on <a href="https://huggingface.co/papers/2504.20571">HuggingFace Daily Papers</a></i>
  <br>
  <i>NeurIPS 2025</i>
  <br>
  <a href="https://arxiv.org/abs/2504.20571">[Arxiv]</a> 
  <a href="https://github.com/ypwang61/One-Shot-RLVR">[Code]</a> 
  <a href="https://wandb.ai/yipingwanguw/verl_few_shot?nw=nwuseryipingwang22">[W&B]</a> 
  <!-- <a href="./pdfs/poster_storyEval_final.pdf",>[Poster]</a> -->
  <a href="https://huggingface.co/collections/ypwang61/one-shot-rlvr">[Models]</a>
  <a href="https://x.com/ypwang61/status/1917596101953348000">[X]</a>
  <a href="pdfs/1-shot_rlvr_v3.pdf">[Slides]</a>
  </p></li>
</ul>
</div>

<ul>
  <li><p>
    <b>FloE: On-the-Fly MoE Inference on Memory-constrained GPU</b>
  <br>
  Yuxin Zhou*, Zheng Li*, Jun Zhang, Jue Wang, <b>Yiping Wang</b>, Zhongle Xie, Ke Chen, Lidan Shou
  <br>
  <i>ICML 2025</i>
  <br>
  <a href="https://arxiv.org/abs/2505.05950">[Arxiv]</a> 
  </p></li>
  </ul>


<div class="boxed">
<ul>
  <li><p>
    <b>Is Your World Simulator a Good Story Presenter? A Consecutive Events-Based Benchmark for Future Long Video Generation</b>
  <br>
  <b>Yiping Wang</b>, Xuehai He, Kuan Wang, Luyao Ma, Jianwei Yang, Shuohang Wang, Simon Shaolei Du, Yelong Shen
  <br>
  <i>CVPR 2025</i>
  <br>
  <a href="https://arxiv.org/abs/2412.16211">[Arxiv]</a> 
  <a href="https://github.com/ypwang61/StoryEval">[Code]</a> 
  <a href="./pdfs/poster_storyEval_final.pdf",>[Poster]</a>
  <a href="https://x.com/ypwang61/status/1877079012742144276">[X]</a>
  <a href="https://ypwang61.github.io/project/StoryEval/">[Website]</a>
  </p></li>
  </ul>
</div>

<ul>
  <li><p>
    <b>Infer Human's Intentions Before Following Natural Language Instructions</b>
  <br>
  Yanming Wan, Yue Wu, <b>Yiping Wang</b>, Jiayuan Mao, Natasha Jaques
  <br>
  <i>AAAI 2025</i>
  <br>
  <a href="https://arxiv.org/abs/2409.18073">[Arxiv]</a> 
    <a href="https://github.com/Simon-Wan/FISER">[Code]</a> 
    <a href="https://x.com/yanming_wan/status/1839495697521070268">[X]</a>
    <a href="https://sites.google.com/view/fiser-hmt/">[Website]</a>
  </p></li>
</ul>


<!-- <h1 style="color: black;">2024</h1> -->

<div class="boxed">
<ul>
<li><p>
  <b>CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning</b>
<br>
<b>Yiping Wang</b>*, Yifang Chen*, Wendan Yan, Alex Fang, Wenjing Zhou, Kevin Jamieson, Simon Shaolei Du 
<br>
<i> NeurIPS 2024  (<font color="red">Spotlight</font>)</i>
<br>
<a href="https://arxiv.org/abs/2405.19547">[Arxiv]</a> 
  <a href="https://github.com/ypwang61/negCLIPLoss_NormSim">[Code]</a> 
  <a href="./pdfs/Poster_negCLIPLoss_NormSim.pdf">[Poster]</a> 
  <a href="https://twitter.com/ypwang61/status/1798396572516151612">[X]</a>
  <a href="https://arxiv.org/abs/2402.02055">[Previous Versions]</a>
</p></li>
</ul>
</div>

<ul>
<li><p>
  <b>JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention</b>
<br>
Yuandong Tian, <b>Yiping Wang</b>, Zhenyu Zhang, Beidi Chen, Simon Shaolei Du <br />
<i>ICLR 2024</i>
<br>
  <a href="https://arxiv.org/abs/2310.00535">[Arxiv]</a>
  <a href="https://twitter.com/tydsh/status/1709785496056930654">[X]</a>
</p></li>
</ul>

<!-- <h1 style="color: black;">2023</h1> -->

<div class="boxed">
<ul>
<li><p>
  <b>Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer</b>
<br>
Yuandong Tian, <b>Yiping Wang</b>, Beidi Chen, Simon Shaolei Du 
<br>
<i>NeurIPS 2023</i> 
(<font color="red">Oral presentation</font> @ ICML2023-HiDL)
<br>
  <a href="https://arxiv.org/abs/2305.16380">[Arxiv]</a>
  <a href="./pdfs/poster_scan_snap.pdf">[Poster]</a>
  <a href="https://twitter.com/tydsh/status/1663611845603885056">[X]</a>
</p></li>
</ul>
</div>

<ul>
<li><p>
  <b>Improved Active Multi-Task Representation Learning via Lasso</b>
<br>
<b>Yiping Wang</b>, Yifang Chen, Kevin Jamieson, Simon S. Du <br />
<i>ICML 2023</i> 
<br>
  <a href="https://arxiv.org/abs/2306.02556">[Arxiv]</a>  
</p></li>
</ul>

<!-- <h1 style="color: black;">2022</h1> -->

<ul>
<li><p>
  <b>C-Mixup: Improving Generalization in Regression</b>
<br>
Huaxiu Yao*, <b>Yiping Wang</b>*, Linjun Zhang, James Zou, Chelsea Finn
<br>
<i>NeurIPS 2022</i>
<br>
  <a href="https://arxiv.org/abs/2210.05775">[Arxiv]</a>
  <a href="https://github.com/huaxiuyao/C-Mixup">[Code]</a>
</p></li>
</ul>


<h1 style="color: black;">Preprints</h1>

<ul>
  <li><p>
    <b>Spurious Rewards: Rethinking Training Signals in RLVR</b>
  <br>
  Rulin Shao*, Shuyue Stella Li*, Rui Xin*, Scott Geng*, <b>Yiping Wang</b>, Sewoong Oh, Simon Shaolei Du, Nathan Lambert, Sewon Min, Ranjay Krishna, Yulia Tsvetkov, Hannaneh Hajishirzi, Pang Wei Koh, Luke Zettlemoyer
  <br>
  <i>Preprint 2025</i>
  <br>
  <a href="https://arxiv.org/abs/2506.10947">[Arxiv]</a> 
  <a href="https://rethink-rlvr.notion.site/Spurious-Rewards-Rethinking-Training-Signals-in-RLVR-1f4df34dac1880948858f95aeb88872f">[Blog1]</a>
  <a href="https://rethink-rlvr.notion.site/Spurious-Rewards-and-Spurious-Prompts-1f4df34dac1880809308c582da4e5d1c">[Blog2]</a>
  <a href="https://github.com/ruixin31/Spurious_Rewards">[Code]</a> 
  <a href="https://wandb.ai/rx31/SpuriousRewardRLVR?nw=nwuserrx31">[W&B]</a> 
  <a href="https://huggingface.co/collections/stellalisy/spurious-rewards">[Models]</a>
  <a href="https://x.com/StellaLisy/status/1927392717593526780">[X]</a>
  </p></li>
</ul>


<ul>
  <li><p>
    <b>SHARP: Accelerating Language Model Inference by SHaring Adjacent layers with Recovery Parameters</b>
  <br>
  <b>Yiping Wang</b>, Hanxian Huang, Yifang Chen, Jishen Zhao, Simon Shaolei Du, Yuandong Tian
  <br>
  <i>preprint 2025</i>
  <br>
  <a href="https://arxiv.org/abs/2502.07832">[Arxiv]</a> 
  </p></li>
</ul>

<ul>
  <li><p>
    <b>Mojito: Motion trajectory and intensity control for video generation</b>
  <br>
  Xuehai He, Shuohang Wang, Jianwei Yang, Xiaoxia Wu, <b>Yiping Wang</b>, Kuan Wang, Zheng Zhan, Olatunji Ruwase, Yelong Shen, Xin Eric Wang
  <br>
  <i>preprint 2024</i>
  <br>
  <a href="https://arxiv.org/abs/2412.08948">[Arxiv]</a> 
  </p></li>
</ul>


</table>
</body>
</html>



